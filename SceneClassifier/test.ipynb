{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(folder):\n",
    "        path = os.path.join(folder, label)\n",
    "        if os.path.isdir(path):\n",
    "            for image_filename in os.listdir(path):\n",
    "                img = cv2.imread(os.path.join(path, image_filename), cv2.IMREAD_GRAYSCALE)\n",
    "                if img is not None:\n",
    "                    images.append(img)\n",
    "                    labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "folder = \"data/15-Scene/00\"\n",
    "images, labels = load_images_from_folder(folder)\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "def extract_sift_features(X):\n",
    "    sift = cv2.SIFT_create()\n",
    "    descriptors = []\n",
    "    for img in X:\n",
    "        kp, des = sift.detectAndCompute(img, None)\n",
    "        descriptors.append(des)\n",
    "    return descriptors\n",
    "\n",
    "train_descriptors = extract_sift_features(X_train)\n",
    "test_descriptors = extract_sift_features(X_test)\n",
    "\n",
    "\n",
    "\n",
    "def build_vocabulary(descriptors_list, k):\n",
    "    all_descriptors = np.vstack(descriptors_list)\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(all_descriptors)\n",
    "    return kmeans\n",
    "\n",
    "k = 100  # 根据需要调整K值\n",
    "vocab_model = build_vocabulary(train_descriptors, k)\n",
    "\n",
    "\n",
    "def features_to_histogram(features, vocab_model):\n",
    "    histogram = np.zeros(len(vocab_model.cluster_centers_))\n",
    "    words = vocab_model.predict(features)\n",
    "    for w in words:\n",
    "        histogram[w] += 1\n",
    "    return histogram\n",
    "\n",
    "def prepare_histograms(descriptors_list, vocab_model):\n",
    "    histograms = []\n",
    "    for descriptors in descriptors_list:\n",
    "        if descriptors is not None:\n",
    "            histogram = features_to_histogram(descriptors, vocab_model)\n",
    "            histograms.append(histogram)\n",
    "        else:\n",
    "            histograms.append(None)\n",
    "    return histograms\n",
    "\n",
    "train_histograms = prepare_histograms(train_descriptors, vocab_model)\n",
    "test_histograms = prepare_histograms(test_descriptors, vocab_model)\n",
    "\n",
    "\n",
    "# 处理可能的None值\n",
    "train_histograms = [hist if hist is not None else np.zeros(k) for hist in train_histograms]\n",
    "test_histograms = [hist if hist is not None else np.zeros(k) for hist in test_histograms]\n",
    "\n",
    "# SVM训练\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "clf = SVC(kernel='linear')  # 可以尝试其他核\n",
    "clf.fit(train_histograms, y_train_encoded)\n",
    "\n",
    "\n",
    "predictions = clf.predict(test_histograms)\n",
    "print(classification_report(y_test_encoded, predictions, target_names=le.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
